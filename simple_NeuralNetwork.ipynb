{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPG95CfAOTx2I73fMOduYx+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wootaehyeon/pytorch-Tutorial/blob/main/simple_NeuralNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "ao3gZTDzXvu2"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, in_features=4, h1=8, h2=9, out_features=3):\n",
        "      super().__init__()\n",
        "      self.fc1 = nn.Linear(in_features, h1)\n",
        "      self.fc2 = nn.Linear(h1, h2)\n",
        "      self.out = nn.Linear(h2, out_features)\n",
        "\n",
        "    def forward(self,x):\n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = F.relu(self.fc2(x))\n",
        "      x = self.out(x)\n",
        "      return x\n"
      ],
      "metadata": {
        "id": "t6VKQlFIIv7f"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(41)\n",
        "model = Model()"
      ],
      "metadata": {
        "id": "BzoUKUwPJWx9"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/0e7a9b0a5d22642a06d3d5b9bcbad9890c8ee534/iris.csv'\n",
        "my_df = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "IVp-Hx2yGaUw"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_df['species'] = my_df['species'].replace('setosa', 0.0)\n",
        "my_df['species'] = my_df['species'].replace('versicolor', 1.0)\n",
        "my_df['species'] = my_df['species'].replace('virginica', 2.0)\n",
        "#change last"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xklcq5M3Gyh7",
        "outputId": "6a6eb645-57e7-43ed-bb11-6820dbf67a45"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-39-3a4c28f35560>:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  my_df['species'] = my_df['species'].replace('virginica', 2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uuVxWnUmG_Zs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = my_df.drop('species', axis=1).to_numpy().astype(np.float32)\n",
        "y = my_df['species'].to_numpy().astype(np.int64)"
      ],
      "metadata": {
        "id": "r3a2UJKpG4Vk"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.values\n",
        "y = y.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "6NxoXdh1HX1h",
        "outputId": "295d46bd-65dd-4cbb-8047-9e5127c1ff5b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'numpy.ndarray' object has no attribute 'values'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-2094f381fce9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'values'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j17SYBWctP0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QMVSCLSFtQDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "wvbFzc5LHcAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=41)"
      ],
      "metadata": {
        "id": "FvRPkqCQHlPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = torch.FloatTensor(X_train)\n",
        "X_test = torch.FloatTensor(X_test)\n",
        "y_train = torch.LongTensor(y_train)\n",
        "y_test = torch.LongTensor(y_test)"
      ],
      "metadata": {
        "id": "3oovYTrSINzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "05CzwczvVw3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set the criterion of model to measure the error\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#Choose Adam Optimizer, lr = learning rate(iff error doesn't go down after)\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr = 0.01)"
      ],
      "metadata": {
        "id": "GVfkBaeAVrN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cdiK4hLyqsOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train our model\n",
        "#Epoch?v(one run thru all the training data in our network)\n",
        "epochs = 100 #100번 반복\n",
        "losses = []\n",
        "for i in range(epochs):\n",
        "  #Go forward and get a prediction\n",
        "  y_pred = model.forward(X_train) #Get predicted results\n",
        "\n",
        "  #Measure the loss/error, gonna\n",
        "  lose = criterion(y_pred,y_train) #predicted values vs the y_train\n",
        "\n",
        "  #keep Track of our losses\n",
        "  losses.append(loss.detach().numpy())\n",
        "\n",
        "  #print every 10 epoch\n",
        "  if i%10 == 0:\n",
        "    print(f'Epoch : {i} and loss: {loss}')\n",
        "\n",
        "  #Do some back propagation: take error rate of forward propagation and feed it back\n",
        "  #thru the network to fine tune the weights\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "metadata": {
        "id": "b-GZTtKjrAYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(epochs),losses)\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')"
      ],
      "metadata": {
        "id": "TG8pbjEd6GVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evalutae Model on Test Data set\n",
        "with torch.no_grad():  #Basically turn off back propagation\n",
        "  y_eval = model.forward(X_test) #X_test are features from our test set,\n",
        "  loss = criterion(y_eval,y_test) #find the loss or error"
      ],
      "metadata": {
        "id": "EjvhBwey7ZO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "with torch.no_grad():\n",
        "  for i , data in enumerate(X_test):\n",
        "    y_val = model.forward(data)\n",
        "\n",
        "    print(f'{i+1}.) {str(y_val)}\\t{y_test[i]}')"
      ],
      "metadata": {
        "id": "JgIz9nw778V_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if y_val.argmax().item() == y_test[i]:\n",
        "  correct += 1\n",
        "print(f'{correct} out of {len(y_test)} = {100*correct/len(y_test)}% correct')"
      ],
      "metadata": {
        "id": "M-EWYfO8IKPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_kEhs1tlLm55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_iris = torch.tensor([4.7,3.2,1.3,0.2])"
      ],
      "metadata": {
        "id": "R6sxcj3NLn9Q"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  print(model(new_iris))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqsUDvhIViCS",
        "outputId": "c7b70d32-4872-47d1-c32b-8d814d9a331b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1756, 0.2740, 0.2870])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Save our NN model\n",
        "torch.save(model.state_dict(),'my_really_awesome_iris_model.pt')\n",
        "\n"
      ],
      "metadata": {
        "id": "yHl4TR_8VzFn"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the saved Model\n",
        "new_model = Model()\n",
        "new_model.load_state_dict(torch.load('my_really_awesome_iris_model.pt'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKA8oGiyWXXj",
        "outputId": "64d196e2-a3a8-4d43-d707-a786302d4375"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-51-9edd1282ac8c>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  new_model.load_state_dict(torch.load('my_really_awesome_iris_model.pt'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Make sure it loaded correctly\n",
        "new_model.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkqPqamcWpEu",
        "outputId": "df86ab07-aea1-4297-d05c-1f8f57a09a61"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (fc1): Linear(in_features=4, out_features=8, bias=True)\n",
              "  (fc2): Linear(in_features=8, out_features=9, bias=True)\n",
              "  (out): Linear(in_features=9, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AWP15q4VXABB"
      }
    }
  ]
}